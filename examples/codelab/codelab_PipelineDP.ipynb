{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1LyGCNZhWBH"
      },
      "source": [
        ":<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/OpenMined/PipelineDP/blob/main/examples/codelab/codelab_PipelineDP.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/OpenMined/PipelineDP/blob/main/examples/codelab/codelab_PipelineDP.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4cUw6Kyiye"
      },
      "source": [
        "#Set-Up\n",
        "Install dependencies, import libraries and set plotting style\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbtnG18myueb"
      },
      "outputs": [],
      "source": [
        "!pip install pipeline-dp apache-beam\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tljm0E_hypU4"
      },
      "outputs": [],
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.runners.portability import fn_api_runner\n",
        "from apache_beam.runners.interactive import interactive_runner\n",
        "from apache_beam.runners.interactive.interactive_beam import *\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import functools\n",
        "from IPython import display\n",
        "import matplotlib\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pipeline_dp\n",
        "import pipeline_dp.private_beam as pbeam\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8yzpKYNbHTF"
      },
      "outputs": [],
      "source": [
        "## https://matplotlib.org/users/style_sheets.html\n",
        "## https://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
        "\n",
        "file_contents = \"\"\"\n",
        "axes.grid: False\n",
        "axes.labelsize: large\n",
        "axes.axisbelow: True\n",
        "\n",
        "# Google Blue, Red, Green, Yellow, Grey\n",
        "# https://material.googleplex.com/style/color.html#color-google-color-palette-guidelines\n",
        "axes.prop_cycle: cycler('color', ['4285F4', 'DB4437', '0F9D58', 'F4B400', '9E9E9E', 'D2691E', 'FF6347', '87CEEB', 'FFC0CB', '32CD32', 'DA70D6', '808000', 'FFD700'])\n",
        "\n",
        "font.size: 14\n",
        "font.family: sans-serif\n",
        "\n",
        "legend.fontsize: large\n",
        "legend.fancybox: True\n",
        "legend.facecolor: FAFBFC\n",
        "legend.frameon: True\n",
        "legend.loc: best\n",
        "\"\"\"\n",
        "\n",
        "# Use a tempfile because matplotlib has to load a file by name or URL\n",
        "import tempfile\n",
        "f = tempfile.NamedTemporaryFile(delete=False)\n",
        "name = f.name\n",
        "f.write(file_contents.encode())\n",
        "f.close()\n",
        "\n",
        "# Load the style sheet\n",
        "# plt.style.use(name)\n",
        "plt.style.use(['seaborn-talk', name])\n",
        "colors=['#4285F4', '#DB4437', '#0F9D58', '#F4B400', '#9E9E9E', '#D2691E', '#FF6347',\n",
        "        '#87CEEB', '#FFC0CB', '#32CD32', '#DA70D6', '#808000', '#FFD700']\n",
        "sns.set_palette(sns.color_palette(colors))\n",
        "# Make plots bigger\n",
        "# plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "\n",
        "# Make plots higher resolution\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4dV3vnQnGeA"
      },
      "outputs": [],
      "source": [
        "#@title Define helper functions for plotting\n",
        "def grouped_bar_chart(group_1: pd.DataFrame, group_2:pd.DataFrame, ax:plt.Axes):\n",
        "  \"\"\"Generates a grouped bar char and returns it.\n",
        "\n",
        "  Args:\n",
        "    group_1: The data of the first group to plot.\n",
        "    group_2: The data of the second group to plot.\n",
        "    ax: The ax object to manipulate.\n",
        "  \"\"\"\n",
        "  labels = group_1['product_view_0']\n",
        "  not_converted_counts = group_1['conversion_value']\n",
        "  converted_counts = group_2['conversion_value']\n",
        "  x = np.arange(len(labels))  # the label locations\n",
        "  width = 0.35  # the width of the bars\n",
        "\n",
        "  rects1 = ax.bar(\n",
        "      x - width / 2,\n",
        "      not_converted_counts,\n",
        "      width,\n",
        "      label='has converted',\n",
        "      color=colors[0])\n",
        "  rects2 = ax.bar(\n",
        "      x + width / 2,\n",
        "      converted_counts,\n",
        "      width,\n",
        "      label='has not converted',\n",
        "      color=colors[1])\n",
        "\n",
        "  ax.set_ylim(bottom=0, top=50)\n",
        "  # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "  ax.set_ylabel('Number of visitors')\n",
        "  ax.set_xlabel('First product viewed')\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels)\n",
        "  return ax, rects1, rects2\n",
        "\n",
        "def private_result_to_df(dp_result: list, metrics: list):\n",
        "  \"\"\"Creates a DataFrame from the differentially private results.\n",
        "\n",
        "  Args:\n",
        "    dp_result: Result of the differentially private aggregation.\n",
        "    metrics: Metrics contained in the result.\n",
        "  \"\"\"\n",
        "  index = [result[0] for result in dp_result]\n",
        "  statistics = [result[1] for result in dp_result]\n",
        "  return pd.DataFrame(statistics, index=index, columns=metrics)\n",
        "\n",
        "\n",
        "def plot_private_and_standard_statistics(df: pd.DataFrame,\n",
        "                                         dp_result: pd.DataFrame,\n",
        "                                         private_metric_name: str,\n",
        "                                         original_metric_name: str,\n",
        "                                         ax: plt.Axes,\n",
        "                                         y_label: str):\n",
        "  \"\"\"Generates a barchart to compare private and non-private statistics.\n",
        "\n",
        "  Args:\n",
        "    df: Original data.\n",
        "    dp_result: Result of the differentially-private aggregation.\n",
        "    private_metric_name: Column name of the private metric.\n",
        "    original_metric_name: Column name of the non-private metric.\n",
        "    ax: Object to plot on.\n",
        "    y_label: Label of y-axis. \n",
        "  \"\"\"\n",
        "  (pd.merge(\n",
        "      df,\n",
        "      dp_result[private_metric_name],\n",
        "      left_index=True,\n",
        "      right_index=True,\n",
        "      how='outer')).rename(\n",
        "          columns={\n",
        "              original_metric_name: f'non-private {private_metric_name}',\n",
        "              private_metric_name: f'differentially private {private_metric_name}'\n",
        "          }).plot(\n",
        "              kind='bar', ax=ax)\n",
        "  ax.legend(bbox_to_anchor=[1, 0.9])\n",
        "  ax.set_ylabel(y_label)\n",
        "  ax.set_xlabel('First product viewed')\n",
        "  return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tRD293xxsFS9"
      },
      "outputs": [],
      "source": [
        "EPSILON = 1 #@param\n",
        "DELTA = 1e-5 #@param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr9X72x4CvCB"
      },
      "source": [
        "# Compute private statistics with PipelineDP\n",
        "\n",
        "Authors: Christiane Ahlheim, Mirac Vuslat Basaran, Vadym Doroshenko, Miguel Guevera, Yurii Sushko\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0trEz2oCztI"
      },
      "source": [
        " # Before you begin\n",
        "\n",
        "Duration: 2:00\n",
        "\n",
        "You might think that aggregate statistics donâ€™t leak any information about the individuals to whom they pertain. However, there are many ways that an attacker can learn sensitive information about individuals from aggregate statistics.\n",
        "\n",
        "In this codelab, you learn how to produce private statistics with differentially private aggregations from PipelineDP to protect individuals' privacy. PipelineDP is a Python framework that lets you apply differential privacy to large datasets with batch-processing systems, such as [Apache Spark](https://spark.apache.org/) and [Apache Beam](https://beam.apache.org/). For more information about how to compute differentially private statistics in [Go](https://go.dev/), see the [Privacy on Beam](https://codelabs.developers.google.com/codelabs/privacy-on-beam#0) codelab.\n",
        "\n",
        "_Private_ means that the output is produced in a way that doesn't leak any private information about the individuals in the data. You can achieve this outcome through _differential privacy_, a strong privacy notion of _anonymization_, which is the process of data aggregation across multiple users to protect user privacy. All anonymization methods use aggregation, but not all aggregation methods achieve anonymization. Differential privacy, on the other hand, provides measurable guarantees about information leakage and privacy.\n",
        "\n",
        "## Prerequisites \n",
        "* Familiarity with Python\n",
        "* Familiarity with basic data aggregation\n",
        "* Experience with pandas, Spark, and Beam\n",
        "\n",
        "## What you'll learn\n",
        "* The basics of differential privacy\n",
        "* How to calculate differentially private summary statistics with PipelineDP.\n",
        "* How to tweak your results with additional privacy and utility parameters.\n",
        "\n",
        "## What you'll need \n",
        "* If you want to run the codelab in your own environment, you need Python 3.7 or higher installed on your computer.\n",
        "* If you want to follow the codelab without your own environment, you need access to [Colaboratory](https://colab.sandbox.google.com/?utm_source=scs-index).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg1H6raPDP-y"
      },
      "source": [
        "# Understand differential privacy\n",
        "\n",
        "Duration: 2:00\n",
        "\n",
        "To better understand differential privacy, look at this simple example.\n",
        "\n",
        "Imagine that you work in the marketing department of an online fashion retailer and you want to understand which of your products are most likely to sell. \n",
        "\n",
        "This chart shows which products the customers looked at first when they visited the shopâ€™s website: t-shirts, jumpers, socks, or jeans. T-shirts are the most popular item while socks are the least popular item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1sSDKsCwDbyn"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df = pd.read_csv('synthetic_customer_journeys.csv', index_col=0)\n",
        "ax = df['product_view_0'].value_counts().sort_index().plot(kind='bar')\n",
        "ax.set_ylabel('Number of visitors')\n",
        "ax.set_xlabel('First product viewed')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szTzpw4RDhtl"
      },
      "source": [
        "This looks useful, but thereâ€™s a catch. When you want to take additional information into account, such as whether customers made a purchase or which product they viewed second, you risk revealing individuals in your data. \n",
        "\n",
        "This chart shows you that only one customer looked at a jumper first and then actually made a purchase:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GfmsoJ4RDr-s"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_grouped_conversion_counts = pd.DataFrame(\n",
        "    df.groupby(['product_view_0',\n",
        "                'has_conversion'])['conversion_value'].count().reset_index())\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax, _, _ = grouped_bar_chart(\n",
        "    df_grouped_conversion_counts[df_grouped_conversion_counts['has_conversion']\n",
        "                                 == True],\n",
        "    df_grouped_conversion_counts[df_grouped_conversion_counts['has_conversion']\n",
        "                                 == False],\n",
        "    ax=ax)\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggt4VZahD0Jg"
      },
      "source": [
        "This isnâ€™t great from a privacy perspective. Anonymized statistics shouldnâ€™t reveal individual contributions, so what do you do? You add random noise to your bar charts to make them a bit less accurate!\n",
        "\n",
        "This bar chart isn't _entirely_ accurate, but it's still useful and it doesn't reveal individual contributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mgxddfdSD2Lp"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "fig, ax = plt.subplots()\n",
        "ax, rects1, rects2 = grouped_bar_chart(\n",
        "    df_grouped_conversion_counts[df_grouped_conversion_counts['has_conversion']\n",
        "                                 == True],\n",
        "    df_grouped_conversion_counts[df_grouped_conversion_counts['has_conversion']\n",
        "                                 == False],\n",
        "                                 ax=ax)\n",
        "ax.legend()\n",
        "\n",
        "def animate(frame):\n",
        "  \"\"\"Function to create animations.\"\"\"\n",
        "  rng = np.random.default_rng()\n",
        "  noise = rng.laplace(size=len(df_grouped_conversion_counts), scale=1)\n",
        "\n",
        "  heights_no_conversion = df_grouped_conversion_counts[\n",
        "      df_grouped_conversion_counts['has_conversion'] ==\n",
        "      False]['conversion_value'].values\n",
        "\n",
        "  heights_conversion = df_grouped_conversion_counts[\n",
        "      df_grouped_conversion_counts['has_conversion'] ==\n",
        "      True]['conversion_value'].values\n",
        "      \n",
        "  for index, b in enumerate(rects1):\n",
        "    b.set_height(heights_conversion[index]+ noise[index])\n",
        "\n",
        "  noise = rng.laplace(size=len(df_grouped_conversion_counts), scale=1)\n",
        "  for index, b in enumerate(rects2):\n",
        "    b.set_height(heights_no_conversion[index] + noise[index])\n",
        "\n",
        "ani = matplotlib.animation.FuncAnimation(\n",
        "    fig,\n",
        "    animate,\n",
        "    frames=200,\n",
        "    interval=10,\n",
        "    repeat=True,\n",
        "    blit=False)\n",
        "plt.close()\n",
        "\n",
        "html = display.HTML(ani.to_html5_video())\n",
        "display.display(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP9OXBYXEBll"
      },
      "source": [
        "_Differential privacy is the addition of the right amount of random noise to mask individual contributions._\n",
        "\n",
        "This example is oversimplified. The proper implementation of differential privacy is more involved and comes with a number of unexpected implementation subtleties. Similar to cryptography, it might not be a great idea to create your own implementation of differential privacy. Instead, you can use PipelineDP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHLWAXQoEFsr"
      },
      "source": [
        "# Download and install PipelineDP\n",
        "\n",
        "Duration: 1:00\n",
        "\n",
        "You donâ€™t need to install PipelineDP follow this codelab because you can find all the relevant code and graphs in this document. \n",
        "\n",
        "To play with PipelineDP, run it yourself, or use it later:\n",
        "\n",
        "\n",
        "\n",
        "* Download and install PipelineDP:\n",
        "\n",
        "    ```\n",
        "pip install pipeline-dp\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can find the code for this codelab and the dataset in the `PipelineDP/examples/codelab/` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2T_OrfUEXah"
      },
      "source": [
        "# Compute conversion metrics per first product viewed \n",
        "Duration: 10:00\n",
        "\n",
        "Imagine that you work at an online fashion retailer and you want to understand which of your different product categories generate the highest number and value of conversions when viewed first. You want to share this information with your marketing agency as well as other internal teams, but you want to prevent the leak of information about any individual customer.\n",
        "\n",
        "To compute conversion metrics per first product viewed for the website:\n",
        "\n",
        "\n",
        "\n",
        "1. Review the mock dataset of visits to your website in the `PipelineDP/examples/codelab/` directory.\n",
        "\n",
        "    This screenshot is an example of the dataset. It contains the user's ID, the products that a user viewed, whether the visitor converted, and, if so, the value of the conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3drtTE8TEbgp"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWtnmM3EtQl"
      },
      "source": [
        "You're interested in these metrics:\n",
        "\n",
        "* `view_counts`: The number of times that your website's visitors see each product first.\n",
        "* `total_conversion_value`: The total amount of money that visitors spend when they convert.\n",
        "* `conversion_rate`: The rate at which visitors convert. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeX8eK9kFR4t"
      },
      "source": [
        "2. Generate the metrics in a non-private way:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SFftV16E5GB"
      },
      "outputs": [],
      "source": [
        "conversion_metrics = df.groupby(['product_view_0'\n",
        "                                ])[['conversion_value', 'has_conversion']].agg({\n",
        "                                    'conversion_value': [len, np.sum],\n",
        "                                    'has_conversion': np.mean\n",
        "                                })\n",
        "conversion_metrics = conversion_metrics.rename(\n",
        "    columns={\n",
        "        'len': 'view_counts',\n",
        "        'sum': 'total_conversion_value',\n",
        "        'mean': 'conversion_rate'\n",
        "    }).droplevel(\n",
        "        0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5LuycLIJFp53"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "_, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)\n",
        "conversion_metrics['view_counts'].plot(\n",
        "    kind='bar', title='view counts', xlabel='first product viewed', ax=axes[0])\n",
        "conversion_metrics['total_conversion_value'].plot(\n",
        "    kind='bar',\n",
        "    title='total conversion value',\n",
        "    xlabel='first product viewed',\n",
        "    ax=axes[1])\n",
        "conversion_metrics['conversion_rate'].plot(\n",
        "    kind='bar',\n",
        "    title='conversion rate',\n",
        "    xlabel='first product viewed',\n",
        "    ax=axes[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6vDSvgSSaPY"
      },
      "source": [
        "As you learned earlier, these statistics can reveal information about individuals in your dataset.Â For instance, only one person converted after the person saw a jumper first. For 22 views, your conversion rate is approximately 0.05. Now you need to transform each bar chart into a private one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3NTtowR0v8B"
      },
      "source": [
        "3. Define your _privacy parameters_ with the `pipeline_dp.NaiveBudgetAccountant` class, and then specify the `epsilon` and `delta` arguments that you want to use for your analysis. \n",
        "\n",
        "   How you set these arguments depends on your particular problem. To  learn more about them, see [Optional: Tweak the differential-privacy parameters] (#optional-tweak-the-differential-privacy-parameters). \n",
        "    \n",
        "  This code snippet uses example values:\n",
        "\n",
        "    ```\n",
        "    budget_accountant = pipeline_dp.NaiveBudgetAccountant(total_epsilon=1 \n",
        "                                                          total_delta=1e-5)\n",
        "    ```\n",
        "\n",
        "\n",
        "4. Initialize the `LocalBackend` instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2LdHxF_0o7-"
      },
      "outputs": [],
      "source": [
        "ops = pipeline_dp.LocalBackend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stsqv1KqSUpO"
      },
      "source": [
        "  You can use the `LocalBackend` instance because you run this program locally without additional frameworks, such as Beam or Spark.\n",
        "\n",
        "\n",
        "\n",
        "5. Initialize the `DPEngine` instance:\n",
        "\n",
        "    ```\n",
        "dp_engine = pipeline_dp.DPEngine(budget_accountant, ops)\n",
        "```\n",
        "\n",
        "    PipelineDP lets you specify further parameters through the `pipeline_dp.AggregateParams` class, which affects the generation of your private statistics. \n",
        "\n",
        "    ```\n",
        "params = pipeline_dp.AggregateParams(\n",
        "     noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "     metrics=[pipeline_dp.Metrics.COUNT],\n",
        "     max_partitions_contributed=1,\n",
        "     max_contributions_per_partition=1)\n",
        "```\n",
        "\n",
        "6. Specify that you want to calculate the `count` metric and use the `LAPLACE` noise distribution.\n",
        "7. Set the `max_partitions_contributed` argument to a `1` value.\n",
        "\n",
        "    This argument bounds how many different visits a user can contribute. You expect users to visit the website once per day and you donâ€™t care whether they visit it multiple times over the course of the day.\n",
        "\n",
        "8. Set the `max_contributions_per_partitions` argument to a `1` value.\n",
        "\n",
        "    This argument specifies how many contributions a single visitor can make to an individual partition or a product category in this case.\n",
        "\n",
        "9. Create a `data_extractor` instance that specifies where to find the `privacy_id`, `partition`, and `value` fields. \n",
        "\n",
        "    Your code should look like this code snippet: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41-qu2eHTT5W"
      },
      "outputs": [],
      "source": [
        "def run_pipeline(data,\n",
        "                 ops,\n",
        "                 total_epsilon=1,\n",
        "                 total_delta=1e-9,\n",
        "                 public_partitions=None):\n",
        "  \"\"\"Calculates differentially private count.\n",
        "\n",
        "  This function takes in the data and the initialised privacy backend, privacy \n",
        "  parameters and (optional) public partitions and calculates the differentially-\n",
        "  private count.\n",
        "\n",
        "  Args:\n",
        "    data: Data to use for the count-calculation.\n",
        "    ops: Initialised privacy backend.\n",
        "    total_epsilon: Epsilon to use for the calculation.\n",
        "    total_delta: Delta to use for the calculation.\n",
        "    public_partitions: If defined, will used those as public partitions in the\n",
        "      private count calculation.\n",
        "  \"\"\"\n",
        "  budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "      total_epsilon=total_epsilon, total_delta=total_delta)\n",
        "\n",
        "  dp_engine = pipeline_dp.DPEngine(budget_accountant, ops)\n",
        "\n",
        "  params = pipeline_dp.AggregateParams(\n",
        "      noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "      metrics=[pipeline_dp.Metrics.COUNT],\n",
        "      max_partitions_contributed=1,\n",
        "      max_contributions_per_partition=1,\n",
        "      public_partitions=public_partitions)\n",
        "\n",
        "  data_extractors = pipeline_dp.DataExtractors(\n",
        "      privacy_id_extractor=lambda row: row.user_id,\n",
        "      partition_extractor=lambda row: row.product_view_0,\n",
        "      value_extractor=lambda row: row.has_conversion)\n",
        "\n",
        "  dp_result = dp_engine.aggregate(data, params, data_extractors)\n",
        "\n",
        "  budget_accountant.compute_budgets()\n",
        "\n",
        "  return dp_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaZR0YZhTobj"
      },
      "source": [
        "10. Add this code to transform your Pandas DataFrame into a list of rows from which you can directly calculate differentially private statistics:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waduSrxx0TPy"
      },
      "outputs": [],
      "source": [
        "rows = [index_row[1] for index_row in df.iterrows()]\n",
        "\n",
        "dp_result_local = run_pipeline(\n",
        "    rows, ops, total_epsilon=EPSILON, total_delta=DELTA)  # returns generator\n",
        "dp_result_local = list(dp_result_local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMW5gwQSn6Oi"
      },
      "source": [
        "Congratulations! You calculated your first differentially private statistic!\n",
        "\n",
        "This chart shows the result of your differentially private count next to the non-private count that you calculated earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8VWh9HnsWOAG"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "dp_result_local = private_result_to_df(\n",
        "    dp_result=dp_result_local, metrics=['count'])\n",
        "_, ax = plt.subplots()\n",
        "ax = plot_private_and_standard_statistics(\n",
        "    df=df['product_view_0'].value_counts().sort_index(),\n",
        "    dp_result=dp_result_local,\n",
        "    private_metric_name='count',\n",
        "    original_metric_name='product_view_0',\n",
        "    ax=ax,\n",
        "    y_label='Number of visitors')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAY-LUqkW4du"
      },
      "source": [
        "The bar chart that you get when you run the code might differ from this one, which is okay. Due to the noise in differential privacy, you get a different bar chart each time that you run the code, but you can see that they're similar to the original non-private bar chart.\n",
        "\n",
        "Please note that it's very important for the privacy guarantees to not run the pipeline multiple times for the sake of privacy guarantees. For more information, see [Compute multiple statistics](#compute-multiple-statistics).\n",
        "\n",
        "\n",
        "# Use public partitions\n",
        "\n",
        "Duration: 7:00\n",
        "\n",
        "In the previous section, you might have noticed that you dropped all visits data for a partition, namely visitors that first saw socks on your website. \n",
        "\n",
        "This is due to partition selection or thresholding, an important step to ensure differential-privacy guarantees when the existence of output partitions depends on the user data itself. When this is the case, the mere existence of a partition in the output can leak the existence of an individual user in the data. To learn more about why this violates privacy, see [this blog post](https://desfontain.es/privacy/almost-differential-privacy.html). To prevent this privacy violation, PipelineDP only keeps partitions with a sufficient number of users in them.\n",
        "\n",
        "When the list of output partitions doesn't depend on private user data, you donâ€™t need this partition-selection step. This is actually the case for your example because you know all possible product categories that a customer could see first.\n",
        "\n",
        "To use partitions:\n",
        "\n",
        "1. Create a list of your possible partitions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuyF14zlYC6m"
      },
      "outputs": [],
      "source": [
        "public_partitions_products = ['jeans', 'jumper', 'socks', 't-shirt']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwOEpygbYhnF"
      },
      "source": [
        "2. Pass the list to the `run_pipeline()` function: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b2yGteOYJhM"
      },
      "outputs": [],
      "source": [
        "ops = pipeline_dp.LocalBackend()\n",
        "dp_result_local_w_public_partitions = run_pipeline(\n",
        "    rows, ops,\n",
        "    total_epsilon=EPSILON,\n",
        "    total_delta=0,\n",
        "    public_partitions=public_partitions_products)  # returns generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToCpVK7fYTfY"
      },
      "source": [
        "  This sets it as an additional input to the `pipeline_dp.AggregateParams` class:\n",
        "\n",
        "```\n",
        "params = pipeline_dp.AggregateParams(\n",
        "     noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "     metrics=[pipeline_dp.Metrics.COUNT],\n",
        "     max_partitions_contributed=1,\n",
        "     max_contributions_per_partition=1,\n",
        "     public_partitions=public_partitions_products)\n",
        "```\n",
        "\n",
        "  If you use public partitions and `LAPLACE` noise, it's possible to set the `total_delta` argument to a `0` value.\n",
        "\n",
        "  Now you see in the result that data for all partitions, or products, is reported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7NJKIlNKXrvS"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "dp_result_local_w_public_partitions = private_result_to_df(\n",
        "    dp_result=list(dp_result_local_w_public_partitions), metrics=['count'])\n",
        "\n",
        "comparison_private_counts_public_partitions = pd.merge(\n",
        "    dp_result_local.rename({'count': 'differentially private count'}, axis=1),\n",
        "    dp_result_local_w_public_partitions.rename(\n",
        "        {'count': 'differentially private count\\n with public partitions'},\n",
        "        axis=1),\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how='outer')\n",
        "comparison_private_counts_public_partitions = pd.merge(\n",
        "    df['product_view_0'].value_counts().sort_index().rename(\n",
        "        'non-private count', inplace=True),\n",
        "    comparison_private_counts_public_partitions,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how='outer')\n",
        "\n",
        "ax = comparison_private_counts_public_partitions.plot(kind='bar')\n",
        "ax.legend(bbox_to_anchor=[1, 0.9])\n",
        "ax.set_ylabel('Number of visitors')\n",
        "ax.set_xlabel('First product viewed')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UjT1BJRhPfb"
      },
      "source": [
        "Not only do public partitions let you keep more partitions, but they also add roughly half as much noise because you don't spend any privacy budget on partition selection, so the difference between raw and private counts is slightly less compared to the previous run.\n",
        "\n",
        "There are two important things to keep in mind when you use public partitions:\n",
        "\n",
        "\n",
        "\n",
        "* Be careful when you derive the list of partitions from raw data. If you don't do this in a differentially private way, your pipeline no longer provides differential privacy guarantees. For more information, see [Advanced: Derive partitions from data](#advanced-derive-partitions-from-data).\n",
        "* If there's no data for some of the public partitions, you need to apply noise to those partitions to preserve differential privacy. For example, if you used an additional product like trousers, which doesnâ€™t occur in your dataset or on your website, it's still noise and the results might show some visits to products when there were none.\n",
        "\n",
        "\n",
        "## Advanced: Derive partitions from data\n",
        "\n",
        "If you run multiple aggregations with the same list of non-public output partitions in the same pipeline, you can derive the list of partitions once with the `dp_engine.select_private_partitions() `method and supply the partitions to each aggregation as the `public_partitions` input. Not only is this safe from a privacy perspective, but it also lets you add less noise because you only use the privacy budget on partition selection _once_ for the entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yLjTkdQhVPd"
      },
      "outputs": [],
      "source": [
        "def get_private_product_views(data, ops):\n",
        "  \"\"\"Obtains the list of product_views in a private manner.\n",
        "\n",
        "    This does not calculate any private metrics; it merely obtains the list of\n",
        "    product_views but does so making sure the result is differentially private.\n",
        "  \n",
        "  Args:\n",
        "    data: Data to derive public partitions from.\n",
        "    ops: Initialised privacy backend.\n",
        "  \"\"\"\n",
        "\n",
        "  # Set the total privacy budget.\n",
        "  budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "      total_epsilon=EPSILON, total_delta=DELTA)\n",
        "\n",
        "  # Create a DPEngine instance.\n",
        "  dp_engine = pipeline_dp.DPEngine(budget_accountant, ops)\n",
        "\n",
        "  # Specify how to extract privacy_id, partition_key and value from a single\n",
        "  # element.\n",
        "  data_extractors = pipeline_dp.DataExtractors(\n",
        "      partition_extractor=lambda row: row.product_view_0,\n",
        "      privacy_id_extractor=lambda row: row.user_id)\n",
        "\n",
        "  # Run aggregation.\n",
        "  dp_result = dp_engine.select_partitions(\n",
        "      data,\n",
        "      pipeline_dp.SelectPartitionsParams(max_partitions_contributed=1),\n",
        "      data_extractors=data_extractors)\n",
        "\n",
        "  budget_accountant.compute_budgets()\n",
        "  return dp_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv06nlaQlImO"
      },
      "source": [
        "# Compute multiple statistics \n",
        "\n",
        "Duration: 12:00\n",
        "\n",
        "Now that you know how PipelineDP works, you can see how you can use it for some more advanced use cases. As mentioned at the beginning, you're interested in three statistics. PipelineDP lets you compute multiple statistics at the same time as long as those share the same parameters in the `AggregateParams` instance, which you see later. Not only is it cleaner and easier to calculate multiple metrics in one go, it's also better in terms of privacy. \n",
        "\n",
        "If you remember the `epsilon` and `delta` parameters that you supply to the `NaiveBudgetAccountant` class, they represent something called a _privacy budget_, which is a measure of the amount of user privacy that you leak from the data.\n",
        "\n",
        "An important thing to remember about the privacy budget is that it's additive. If you run a pipeline with a particular epsilon Îµ and delta Î´ a single time, you spend an (Îµ,Î´) budget. If you run it a second time, you spend a total budget of (2Îµ, 2Î´). Similarly, if you compute multiple statistics with a `NaiveBudgetAccountant` method and consecutively a privacy budget of Îµ,Î´, you spend a total budget of (2Îµ, 2Î´). This means that you degrade the privacy guarantees.\n",
        "\n",
        "To circumvent this, you need to use a single `NaiveBudgetAccountant` instance with the total budget that you want to use when you need to compute multiple statistics over the same data. You then need to specify the `epsilon` and `delta` values that you want to use for each aggregation. In the end, you end up with the same overall privacy guarantee, but the higher `epsilon` and `delta` values that a particular aggregation has, the higher accuracy it has.\n",
        "\n",
        "To see this in action, you can compute the `count`, `mean`, and `sum` statistics. \n",
        "\n",
        "You calculate statistics on top of two different metrics: a `conversion_value` metric, which you use to infer the amount of revenue generated based on which product is viewed first, and a `has_conversion` metric, which you use to calculate the number of visitors to your website and the average conversion rate. \n",
        "\n",
        "For each metric, you need to separately specify the parameters that guide the calculation of the private statistics. You split your privacy budget across the two metrics. You calculate two statistics from the `has_conversion` metric, so you want to assign it two-thirds of your initial budget and assign the other one-third to the `conversion_value` metric. \n",
        "\n",
        "To compute multiple statistics:\n",
        "\n",
        "\n",
        "1. Set up your privacy budget accountant with the total `epsilon` and `delta` values that you want to use across the three statistics:\n",
        "\n",
        "    ```\n",
        "budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "     total_epsilon=1, total_delta=0)\n",
        "```\n",
        "\n",
        "\n",
        "2. Initialize the `DPEngine` to calculate the conversion value defined as sum over conversions by product:\n",
        "\n",
        "    ```\n",
        " dp_engine_conversion_value_metrics = pipeline_dp.DPEngine(\n",
        "     budget_accountant, ops)\n",
        "```\n",
        "\n",
        "\n",
        "3. Specify the parameters for this metric.\n",
        "\n",
        "    ```\n",
        " params_conversion_value_metrics = pipeline_dp.AggregateParams(\n",
        "     noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "     metrics=[pipeline_dp.Metrics.SUM],\n",
        "     max_partitions_contributed=1,\n",
        "     max_contributions_per_partition=1,\n",
        "     min_value=0,\n",
        "     max_value=100,\n",
        "     public_partitions=public_partitions_products,\n",
        "     budget_weight=1/3)\n",
        "```\n",
        "\n",
        "    The last argument optionally specifies the weight of your privacy budget.  You could give the same weight to all, but you want to set this argument to one-third as explained earlier. \n",
        "\n",
        "    You also set a `min_value` and `max_value` argument to specify the lower and upper bound applied to a value contributed by a unit of privacy in a partition. These parameters are required when you want to calculate a private sum or mean. You donâ€™t expect negative values, so you can assume `0` and `100` as reasonable bounds.\n",
        "\n",
        "\n",
        "4. Extract the relevant data and then pass it to the aggregation function:\n",
        "\n",
        "    ```\n",
        " data_extractors_conversion_value_metrics = pipeline_dp.DataExtractors(\n",
        "     privacy_id_extractor=lambda row: row.user_id,\n",
        "     partition_extractor=lambda row: row.product_view_0,\n",
        "     value_extractor=lambda row: row.conversion_value)\n",
        "\n",
        " dp_result_conversion_value_metrics = (\n",
        "     dp_engine_conversion_value_metrics.aggregate(\n",
        "         data, params_conversion_value_metrics,\n",
        "         data_extractors_conversion_value_metrics))\n",
        "```\n",
        "\n",
        "\n",
        "5. Follow the same steps to calculate the two metrics based on your `has_conversion` variable: \n",
        "\n",
        "    ```\n",
        "dp_engine_conversion_rate_metrics = pipeline_dp.DPEngine(\n",
        "     budget_accountant, ops)\n",
        "     ```\n",
        "     ```\n",
        "params_conversion_rate_metrics = pipeline_dp.AggregateParams(\n",
        "     noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "     metrics=[pipeline_dp.Metrics.COUNT, pipeline_dp.Metrics.MEAN],\n",
        "     max_partitions_contributed=1,\n",
        "     max_contributions_per_partition=1,\n",
        "     min_value=0,\n",
        "     max_value=1,\n",
        "     public_partitions=public_partitions_products,\n",
        "     budget_weight=2/3)\n",
        "     ```\n",
        "     ```\n",
        " data_extractors_conversion_rate_metrics = pipeline_dp.DataExtractors(\n",
        "     privacy_id_extractor=lambda row: row.user_id,\n",
        "     partition_extractor=lambda row: row.product_view_0,\n",
        "     value_extractor=lambda row: row.has_conversion)\n",
        "     ```\n",
        "     ```\n",
        " dp_result_conversion_rate_metrics = (\n",
        "     dp_engine_conversion_rate_metrics.aggregate(\n",
        "         data, params_conversion_rate_metrics,\n",
        "         data_extractors_conversion_rate_metrics))\n",
        "```\n",
        "\n",
        "    The only change is in the `pipeline_dp.AggregateParams` instance, in which you now define `mean` and `count` as aggregations, and assign two-thirds of your privacy budget to this calculation. Because you want to have the same contribution bounds for both statistics and calculate them on top of the same `has_conversion` variable, you can combine them in the same `pipeline_dp.AggregateParams` instance and calculate them at the same time.\n",
        "\n",
        "\n",
        "6. Call the `budget_accountant.compute_budgets()` method:\n",
        "\n",
        "    ```\n",
        "budget_accountant.compute_budgets()\n",
        "```\n",
        "\n",
        "You can plot all three private statistics in comparison to their original statistics. Depending on the noise added, you see that the results can actually fall outside of the plausible scale. In this instance, you see a negative conversion rate and total conversion value for jumpers because the noise added is symmetric around zero. For further analyses and processing, it's best to not manually post-process the private statistics, but if you wanted to add those plots to a report, you could simply set the minimum to zero afterward without violation of the privacy guarantees. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yssgM0Nf2ffD"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Function to calculate multiple statistics\n",
        "def run_pipeline_multiple_statistics(data,\n",
        "                                     ops,\n",
        "                                     total_epsilon=EPSILON,\n",
        "                                     total_delta=DELTA,\n",
        "                                     public_partitions=None):\n",
        "  \"\"\"Calculates three differentially private statistics.\n",
        "\n",
        "  This function takes in the data and the initialised privacy backend, privacy \n",
        "  parameters and (optional) public partitions and calculates the differentially-\n",
        "  private count, sum, and mean.\n",
        "\n",
        "  Args:\n",
        "    data: Data to use for the count-calculation.\n",
        "    ops: Initialised privacy backend.\n",
        "    total_epsilon: Epsilon to use for the calculation.\n",
        "    total_delta: Delta to use for the calculation.\n",
        "    public_partitions: If defined, will used those as public partitions in the\n",
        "      private count calculation.\n",
        "  \"\"\"\n",
        "\n",
        "  budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "      total_epsilon=total_epsilon, total_delta=total_delta)\n",
        "\n",
        "  dp_engine_conversion_value_metrics = pipeline_dp.DPEngine(\n",
        "      budget_accountant, ops)\n",
        "\n",
        "  params_conversion_value_metrics = pipeline_dp.AggregateParams(\n",
        "      noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "      metrics=[pipeline_dp.Metrics.SUM],\n",
        "      max_partitions_contributed=1,\n",
        "      max_contributions_per_partition=1,\n",
        "      min_value=0,\n",
        "      max_value=100,\n",
        "      public_partitions=public_partitions,\n",
        "      budget_weight=1/3)\n",
        "\n",
        "  data_extractors_conversion_value_metrics = pipeline_dp.DataExtractors(\n",
        "      privacy_id_extractor=lambda row: row.user_id,\n",
        "      partition_extractor=lambda row: row.product_view_0,\n",
        "      value_extractor=lambda row: row.conversion_value)\n",
        "\n",
        "  dp_result_conversion_value_metrics = (\n",
        "      dp_engine_conversion_value_metrics.aggregate(\n",
        "          data, params_conversion_value_metrics,\n",
        "          data_extractors_conversion_value_metrics))\n",
        "\n",
        "  dp_engine_conversion_rate_metrics = pipeline_dp.DPEngine(\n",
        "      budget_accountant, ops)\n",
        "\n",
        "  params_conversion_rate_metrics = pipeline_dp.AggregateParams(\n",
        "      noise_kind=pipeline_dp.NoiseKind.LAPLACE,\n",
        "      metrics=[pipeline_dp.Metrics.COUNT, pipeline_dp.Metrics.MEAN],\n",
        "      max_partitions_contributed=1,\n",
        "      max_contributions_per_partition=1,\n",
        "      min_value=0,\n",
        "      max_value=1,\n",
        "      public_partitions=public_partitions,\n",
        "      budget_weight=2/3)\n",
        "\n",
        "  data_extractors_conversion_rate_metrics = pipeline_dp.DataExtractors(\n",
        "      privacy_id_extractor=lambda row: row.user_id,\n",
        "      partition_extractor=lambda row: row.product_view_0,\n",
        "      value_extractor=lambda row: row.has_conversion)\n",
        "\n",
        "  dp_result_conversion_rate_metrics = (\n",
        "      dp_engine_conversion_rate_metrics.aggregate(\n",
        "          data, params_conversion_rate_metrics,\n",
        "          data_extractors_conversion_rate_metrics))\n",
        "\n",
        "  budget_accountant.compute_budgets()\n",
        "\n",
        "  return dp_result_conversion_value_metrics, dp_result_conversion_rate_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IzInL1oemBvw"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Calculate all 3 statistics\n",
        "\n",
        "ops = pipeline_dp.LocalBackend()\n",
        "dp_result_conversion_value_metrics, dp_result_conversion_rate_metrics = run_pipeline_multiple_statistics(\n",
        "    rows,\n",
        "    ops,\n",
        "    total_epsilon=EPSILON,\n",
        "    total_delta=0,\n",
        "    public_partitions=public_partitions_products)  # returns generator\n",
        "\n",
        "dp_result_conversion_value_metrics = list(dp_result_conversion_value_metrics)\n",
        "dp_result_conversion_rate_metrics = list(dp_result_conversion_rate_metrics)\n",
        "\n",
        "dp_result_conversion_rate_metrics = private_result_to_df(\n",
        "    dp_result_conversion_rate_metrics, metrics=['mean', 'count'])\n",
        "dp_result_conversion_value_metrics = private_result_to_df(\n",
        "    dp_result_conversion_value_metrics, metrics=['sum'])\n",
        "all_private_statistics = pd.merge(\n",
        "    dp_result_conversion_rate_metrics,\n",
        "    dp_result_conversion_value_metrics,\n",
        "    right_index=True,\n",
        "    left_index=True,\n",
        "    how='outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A2T9qcU223ma"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Plot all 3 statistics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)\n",
        "\n",
        "axes[0] = plot_private_and_standard_statistics(\n",
        "    df=conversion_metrics['view_counts'],\n",
        "    dp_result=all_private_statistics,\n",
        "    private_metric_name='count',\n",
        "    original_metric_name='view_counts',\n",
        "    ax=axes[0],\n",
        "    y_label='Number of visitors')\n",
        "axes[0].legend('')\n",
        "\n",
        "axes[1] = plot_private_and_standard_statistics(\n",
        "    df=conversion_metrics['conversion_rate'],\n",
        "    dp_result=all_private_statistics,\n",
        "    private_metric_name='mean',\n",
        "    original_metric_name='conversion_rate',\n",
        "    ax=axes[1],\n",
        "    y_label='Conversion rate')\n",
        "axes[1].legend('')\n",
        "\n",
        "axes[2] = plot_private_and_standard_statistics(\n",
        "    df=conversion_metrics['total_conversion_value'],\n",
        "    dp_result=all_private_statistics,\n",
        "    private_metric_name='sum',\n",
        "    original_metric_name='total_conversion_value',\n",
        "    ax=axes[2],\n",
        "    y_label='Sum of conversion values')\n",
        "axes[2].legend(['non-private statistic', 'differentially private\\n statistic'],\n",
        "               bbox_to_anchor=(1, 0.9))\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmHfSLMXmujX"
      },
      "source": [
        "# Run the pipeline with Beam \n",
        "\n",
        "Duration: 8:00\n",
        "\n",
        "Data processing nowadays requires you to deal with huge amounts of data, so much so that you can't process it locally. Instead, many people use frameworks for large-scale data processing, such as Beam or Spark, and run their pipelines in the cloud.\n",
        "\n",
        "PipelineDP supports Beam and Spark with only small changes to your code.\n",
        "\n",
        "To run the pipeline with Beam with the `private_beam` API:\n",
        "\n",
        "\n",
        "1. Initialize a `runner` variable and then create a pipeline in which you apply your privacy operations to a Beam representation of your `rows`:\n",
        "\n",
        "    ```\n",
        "runner = fn_api_runner.FnApiRunner()  # local runner\n",
        "\n",
        "  with beam.Pipeline(runner=runner) as pipeline:\n",
        "     beam_data = pipeline | beam.Create(rows)\n",
        "```\n",
        "\n",
        "\n",
        "2. Create a `budget_accountant` variable with your required privacy parameters:\n",
        "\n",
        "    ```\n",
        "budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "               total_epsilon=1, total_delta=0)\n",
        "```\n",
        "\n",
        "3. Create a `pcol`, or private collection, variable, which guarantees that any aggregations conform with your privacy requirements:\n",
        "\n",
        "    ```\n",
        "pcol = beam_data | pbeam.MakePrivate(\n",
        "                                 budget_accountant=budget_accountant,\n",
        "                                 privacy_id_extractor=lambda row: row.user_id)\n",
        "```\n",
        "\n",
        "\n",
        "4. Specify the parameters of your private aggregation in the appropriate class. \n",
        "\n",
        "    Here, you use the  `pipeline_dp.aggregate_params.SumParams()`class because you calculate the sum of product views.\n",
        "\n",
        "5. Pass your aggregation parameters to `pbeam.Sum` method to calculate your statistic:\n",
        "\n",
        "    ```\n",
        "dp_result = pcol | pbeam.Sum(params)\n",
        "```\n",
        "\n",
        "\n",
        "6. In the end, your code should look like this code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tylHO7onBVb"
      },
      "outputs": [],
      "source": [
        "runner = fn_api_runner.FnApiRunner()  # local runner\n",
        "\n",
        "with beam.Pipeline(runner=runner) as pipeline:\n",
        "  beam_data = pipeline | beam.Create(rows)\n",
        "  budget_accountant = pipeline_dp.NaiveBudgetAccountant(\n",
        "      total_epsilon=EPSILON, total_delta=0)\n",
        "\n",
        "  # Create PrivatePCollection\n",
        "  pcol = beam_data | pbeam.MakePrivate(\n",
        "      budget_accountant=budget_accountant,\n",
        "      privacy_id_extractor=lambda row: row.user_id)\n",
        "\n",
        "  # Create params for counts\n",
        "  params = pipeline_dp.aggregate_params.CountParams(\n",
        "      noise_kind=pipeline_dp.aggregate_params.NoiseKind.LAPLACE,\n",
        "      max_partitions_contributed=1,\n",
        "      max_contributions_per_partition=1,\n",
        "      public_partitions=public_partitions_products,\n",
        "      partition_extractor=lambda row: row.product_view_0)\n",
        "\n",
        "  dp_result = pcol | pbeam.Count(params)\n",
        "\n",
        "  budget_accountant.compute_budgets()\n",
        "\n",
        "  dp_result | beam.Map(print)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Stb7qk6S6Z-Y"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Optional: using framework-independent functions with Beam\n",
        "runner = fn_api_runner.FnApiRunner()  # local runner\n",
        "\n",
        "with beam.Pipeline(runner=runner) as pipeline:\n",
        "  beam_data = pipeline | beam.Create(rows)\n",
        "  ops = pipeline_dp.BeamBackend()\n",
        "  public_partitions_product_views = get_private_product_views(beam_data, ops)\n",
        "  dp_result = run_pipeline(\n",
        "      beam_data,\n",
        "      ops,\n",
        "      total_epsilon=EPSILON,\n",
        "      total_delta=DELTA,\n",
        "      public_partitions=public_partitions_product_views)\n",
        "  dp_result | beam.Map(print)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4ybVIjCZHp"
      },
      "source": [
        "# Optional: Tweak the privacy and utility parameters\n",
        "Duration: 5:00\n",
        "\n",
        "You've seen quite a few parameters mentioned in this codelab, such as the `epsilon`, `delta`, and  `max_partitions_contributed` parameters. You can roughly divide them into two categories: _privacy parameters_ and _utility parameters_.\n",
        "\n",
        "\n",
        "### Privacy parameters \n",
        "\n",
        "The `epsilon` and `delta` parameters quantify the privacy that you provide with differential privacy. More precisely, they're a measure of how much information a potential attacker can gain about the data from the anonymized output. The higher the value of the parameters, the more information the attacker gains about the data, which is a privacy risk. On the other hand, the lower the value of the `epsilon` and `delta` parameters, the more noise you need to add to the output to make it anonymous and the higher the number of unique users that you need in each partition to keep them in the anonymized output. In this case, there's a tradeoff between utility and privacy.\n",
        "\n",
        "In PipelineDP, you need to specify your desired privacy guarantees of your anonymized output when you set the total privacy budget in the `NaiveBudgetAccountant` instance. The caveat is that if you want your privacy guarantees to hold, you need to carefully use a separate `NaiveBudgetAccountant` instance for each aggregation or run the pipeline multiple times to avoid the overuse of your budget.\n",
        "\n",
        "For more information about differential privacy and what the privacy parameters mean, see [A reading list on differential privacy](https://desfontain.es/privacy/differential-privacy-reading-list.html).\n",
        "\n",
        "\n",
        "### Utility parameters \n",
        "\n",
        "Utility parameters don't affect the privacy guarantees, but affect the accuracy and, consequently, the utility of the output. They're provided in the `AggregateParams` instance and used to scale the noise added.\n",
        "\n",
        "A utility parameter provided in the `AggregateParams` instance and applicable to all aggregations is the `max_partitions_contributed` parameter. A partition corresponds to a key of the data that's returned by the PipelineDP aggregation operation, so the` max_partitions_contributed` parameter bounds the number of distinct key values that a user can contribute to the output. If a user contributes to a number of keys that exceeds the value of the `max_partitions_contributed` parameter, some contributions are dropped so that they contribute to the exact value of the `max_partitions_contributed` parameter.\n",
        "\n",
        "Similarly, most aggregations have a `max_contributions_per_partition` parameter. They're also provided in the `AggregateParams` instance` `and each aggregation could have separate values for them. They bound a userâ€™s contribution for each key.\n",
        "\n",
        "The noise added to the output is scaled by the `max_partitions_contributed` and `max_contributions_per_partition` parameters, so there's a tradeoff here: Larger values assigned to each parameter means that you keep more data, but you get a noisier result.\n",
        "\n",
        "Some aggregations require a `min_value` and `max_value` parameter, which specify the bounds for contributions of each user. If a user contributes a value lower than the value assigned to the `min_value` parameter, the value is increased to the value of the parameter. Similarly, if a user contributes a value larger than the value of the `max_value` parameter, the value is decreased to the value of the parameter. To keep more of the original values, you have to specify larger bounds. Noise is scaled by the size of the bounds, so larger bounds let you keep more data, but you end up with a noisier result.\n",
        "\n",
        "Finally, the `noise_kind` parameter supports two different noise mechanisms in PipelineDP: `GAUSSIAN` and `LAPLACE` noise. The `LAPLACE` distribution gives better utility with low contribution bounds, which is why PipelineDP uses it by default. However, if you want to use a `GAUSSIAN` distribution noise, you can specify it in the `AggregateParams` instance.\n",
        "\n",
        "\n",
        "# Congratulations\n",
        "\n",
        "Duration: 0:00\n",
        "\n",
        "Great job! You finished the PipelineDP codelab and learned a lot about differential privacy and PipelineDP.\n",
        "\n",
        "\n",
        "## Learn more \n",
        "*   [GitHub repository](https://github.com/OpenMined/PipelineDP)\n",
        "\n",
        "*   [PipelineDP](https://pipelinedp.io)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yk4cUw6Kyiye"
      ],
      "name": "codelab_PipelineDP.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
